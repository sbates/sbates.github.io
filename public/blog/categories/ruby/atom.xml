<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ruby | Bratty Redhead]]></title>
  <link href="http://blog.brattyredhead.com/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://blog.brattyredhead.com/"/>
  <updated>2013-07-26T15:07:07-05:00</updated>
  <id>http://blog.brattyredhead.com/</id>
  <author>
    <name><![CDATA[Sascha Bates]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ruby Toolchaining Part 3: Walking the Package Talk]]></title>
    <link href="http://blog.brattyredhead.com/blog/2013/05/24/ruby-toolchaining-part-3-walking-the-package-talk/"/>
    <updated>2013-05-24T03:16:00-05:00</updated>
    <id>http://blog.brattyredhead.com/blog/2013/05/24/ruby-toolchaining-part-3-walking-the-package-talk</id>
    <content type="html"><![CDATA[<p>This is the third post in a series about managing your Ruby Toolchain. Expect at least one more after this. You can also read:<br/>
<a href="http://blog.brattyredhead.com/blog/2013/05/12/pieces-and-parts-managing-your-ruby-toolchain">Pieces and Parts: Managing Your Ruby ToolChain(part 1)</a> <br/>
<a href="http://blog.brattyredhead.com/blog/2013/05/17/managing-your-ruby-toolchain-part-2-the-package-repo-rant">Managing Your Ruby Toolchain Part 2: The Package Repo Rant</a></p>

<p>Why I rant about package repositories: Static software without a repository is the pebble that becomes an avalanche. So many undesirable behaviors stem from no one owning the package collection.  Read the rant if you want details.  This is a practical discussion, although I'm not telling you what to do. I'm just telling you what I've done and what I've seen over the course of my career.  There are many ways to solve this problem. Do what works for you.</p>

<p>This post grew so much that there is one more after it that specifically deals with some toolchaining tools and ideas as well as a few anecdotes on how I've dealt with some of these challenges in the past.</p>

<p>Today we're going to talk about:<br/>
<a href="#tarballs">Tarball Orphans vs Artifacts vs Inbetweeners</a>  <br/>
<a href="#internet">The Internet</a><br/>
<a href="#repos">An Approach to Repositories</a>  <br/>
<a href="#packing">Packaging Tarballs</a>  <br/>
<a href="#ruby">Ruby Management</a>   <br/>
<a href="#toolchaining">Ruby Toolchain Management</a></p>

<h2><a id="tarballs">Tarball Orphans</a></h2>

<p>What do I mean when I rant about tarballs? Basically I mean that pile of source you downloaded from the internet, or Tomcat package, JBoss tarball, Ruby source, whatever.</p>

<p>What is exempt from my ranting  wrath? Custom code that you might tar up instead of jar/ear/war.  Anything that changes often shouldn't be in our static package repository. Those are places to keep long term, install-once per server software.</p>

<p>When I talk about tarballs, I mean tumbleweed off the internet.  When I refer to compiled code I'll use the word <strong>artifact</strong>.  What's an artifact? It might be a jar file you bundle with your deployed code. It might be a war file. It might be a tar of ruby code Or database artifacts.  Anything that's your stuff, we don't put that into package repositories.  We put it into artifact repositories like Artifactory and Nexus. People also use S3 storage to store and retrieve artifacts.</p>

<p>Some things may not be easily categorized. Newer products get frequent updates that may require frequent patches or deployments. For example, I worked with a team that implemented Basho's <a href="http://basho.com/">Riak</a> which they updated frequently and ended up engaged in a disagreement with Ops on how often they could update it. The ops team wanted to restrict it to quarterly and the devs wanted much more frequently. This sort of management requires a custom solution that may be package-based or not.</p>

<h2><a id="internet">The Internet</a></h2>

<p>If your infrastructure has free access to the internet, that's awesome. Many infrastructures have limited or no access to the internet.  Often the reasons for this seem silly.  But sometimes you can't fight city hall, or you can but you need to save your fights for the life or death kind.  Your servers don't need the internet to survive. Or they should not.</p>

<p>Eventually you will find yourself needing stuff from the Internet. In order to work within restrictions, you can set up a <a href="http://en.wikipedia.org/wiki/Bastion_host">Bastion</a> host or AWS VPC infrastructure that can call out to the internet in order to create private mirrors of any repositories you need.  You can follow the slightly more difficult path of setting up an internal server that contains your repos that you need to sync in a way that doesn't have direct access to the internet.</p>

<p><strong>Internet as Troublemaker</strong><br/>
Internet access brings its own set of problems as well. If you aren't specific about package versions, with every server provision you could have slightly different versions of things installed.  This is a problem because it can cause erratic behavior across your infrastructure. If you have 1000 nodes built over the course of six months, each build wave can introduce incremental differences. When you control the packages in your internal repos, you exert a stabilizing effect, which is a good way to control your system without making it brittle.</p>

<p>Even if sloppy package management doesn't actually cause issues, it will be a suspect in any intermittent, mysterious problems. Picture an outage conference bridge including execs. Now envision yourself explaining to them how this mismatch isn't a problem. Can you envision any explanation that doesn't make you sound like a dolt?</p>

<p><strong>Example</strong>: A few years ago JBoss 5 shipped with a bug that was a major performance blocker but difficult to track down. It was later fixed in a minor patch release. Imagine having a JBoss package block that just says <code>package "jboss" {action :install}</code> and using an internet repo to install it. 6 months later you provision 100 servers from your trusty internet repo and over your peak season, the bug triggers but everything is weird because it's only a problem on some servers.  Imagine tracking this down. (Yes this is a flawed example b/c as far as I know, there's no internet repo with a JBoss rpm)</p>

<p>If you're a dev and you think this isn't a problem, try chatting with a friend in the sysadmin/ops area before you poo-poo. If you're a sysadmin and you think this isn't a big deal, may we never be responsible for the same infrastructure.</p>

<p><strong>Be Conservative.</strong> As a rule it's ok to use external signed key repositories for your base OS packages as those shouldn't change. Tread carefully even with patch/update servers to ensure homogenous installs and any packages acquired from other internet repos (like EPEL) should be installed with explicit versions.</p>

<p><strong>Adopt Orphans</strong> Don't let Internet-sourced software roam around your infrastructure unsupervised. If you need a package from the internet, it should be easy enough to download and insert into your custom repository. There are several tools for managing repositories. For Enterprise Linux, <a href="https://github.com/cobbler/">Cobbler</a>, the provisioning and infrastructure management tool has repository management and mirroring. My new favorite thing for this though is a tool called <a href="http://pulpproject.org/">Pulp</a>, an open source project by Red Hat.  If you prefer simplicity, you can just install a web proxy and use a command line tool like <code>createrepo</code> to manage your yum repos.</p>

<p><strong>Don't assume I can talk to the Internet.</strong> When it comes to configuration management tools, I find it in bad taste to write a module or cookbook intended for the community with an Internet dependency.  If you have to write one, label the dependency in large font.</p>

<h2><a id="repos">An Approach to Repos</a></h2>

<h3>OS Packages</h3>

<p>If you're going to set up repositories, consider a collection like this list.</p>

<p><strong>Base</strong> - base EL install repo  - This is generally straight up ISO content<br/>
<strong>Patch</strong> - repository containing patches<br/>
<strong>EPEL</strong> - EL Extras repo mirror<br/>
<strong>Custom</strong> - repository containing all the custom packages I need that I've either crafted myself or downloaded</p>

<p><strong>Purity of Purpose:</strong> Always keep your base and patch repos pure. Don't let people just dump random packages into a Base OS collection. You'll never know what was supposed to be there and what was added later.</p>

<p><strong>Prioritization and Specificity:</strong> If you have two versions of a package in different repos, either be specific when installing or configure a priority for each repo.</p>

<h3>Rubygems</h3>

<p>This is where you get/put your gems. Gem is the package manager for Rubygems. You either need to connect to the internet to get all of these things or you need internal package repos/mirrors.  See this <a href="http://davidmoulton.me/2011/02/07/create-a-private-gem-repository.html">blog post</a> by David Moulton for how easy it is to set up a rubygems repo.</p>

<h3>Artifacts</h3>

<p>This is where your deployment artifacts, jar, war, ear files should be contained; a tool where it's easy to retreive them programmatically. I have seen people use <a href="http://www.sonatype.org/nexus/">Nexus</a>, <a href="http://www.jfrog.com/">Artifactory</a> and even S3 to store artifacts. If you're not a java shop, you may not need something this complex. My major experience is with Java shops.</p>

<h3>YMMV</h3>

<p>There are many ways to craft your infrastructure. Having package repositories is an advantage because they make it really obvious to everyone in your organization where to look for software and where they should put software they need.</p>

<p>The important thing to keep in mind here is that, especially if you're in the Enterprise, you aren't designing for yourself or just one team. This will balloon out to include dev teams using your tools. In order to deploy their app, the devs will test using VMs provisioned by your infrastructure and they should be taking advantage of your beautiful repos to deposit their extra software packages.  Your team may even be administering the VM infrastructure.</p>

<p>A major goal to strive for is for all VMs and servers to be provisioned the same way in all environments, desktop to production. You make this easiest and more likely to happen when you make it easy to interact with software repositories.  If it's not easy, other teams will "figure something out" which will likely outrage you when you discover it.</p>

<h2><a id="packing">Practical Tarball Management</a></h2>

<h3>Avoid Compiling From Source</h3>

<p>Believe me when I say that you <strong>do not</strong> want to compile Ruby from scratch every time you build a server. The more automation achievements you unlock, the easier it becomes to use ephemeral VMs.  In Dev, people should be popping up and killing VMs all the time. If it takes 10 minutes to build a server, they won't be doing this, dev VMs will have <a href="http://workstuff.tumblr.com/post/50911984233/some-tips-on-getting-started-with-vagrant-and-chef">major cruft buildup</a> and dismay will ensue when people realize they can't actually reproduce their dev VM.</p>

<h3>Turning a Tarball into a Package</h3>

<p>How do you get packages for your repos when all you have is a pile of tarballs? If you're brilliant, write a package spec for it. If you're like the rest of us, you use <a href="https://github.com/jordansissel/fpm">FPM</a>.  Even if you are in a situation where you can't have a package repo, you can at least create and store packages which will speed up installation and simplify implementation.</p>

<p><a href="https://github.com/jordansissel/fpm">FPM</a>: Learn it, love it, live it.</p>

<h3><a id="ruby">Ruby Management</a></h3>

<h3>Ruby Source</h3>

<p><strong>1.8.7 is EOL</strong><br/>
First, on the topic of existing packages, as <a href="http://www.ruby-lang.org/en/news/2011/10/06/plans-for-1-8-7/">announced in October of 2011</a>, Ruby 1.8.7 is officially end of life and won't even get security updates after June 2013.  <em>Just say no to the supplied 1.8.7 packages</em> on your Enterprise Linux(EL) and the one that comes installed with OSX. No really, never touch it. If you're using it, start seriously considering how to move on.</p>

<p><strong>System Ruby</strong><br/>
Whatever else you're doing, your servers will all want a system Ruby. It's possible to get along without this(see omnibus in subsequent sections), but especially in dev, people will be shocked and dismayed when there's no easily accessible Ruby.  So get you some Ruby, not from the ancient EL repos, but get the source tarball from <a href="http://www.ruby-lang.org/en/">Ruby-Lang.org</a>.</p>

<p>Why do I tell you this obvious thing? We had the brilliant idea of switching out our compile-every-time system ruby install with just using the embedded Ruby that ships with Chef client. Never do this. The trouble is that your Ruby install is not just an executable, but a name space for installing gems and related software. This is is why Chef ships in an omnibus in the first place: to avoid dependency hell and version conflicts.  The other problem with this idea is that you are still lacking a system Ruby. You either have symlink to the Ruby executable or people have to know where to look for. So install a system Ruby independent of any other software.</p>

<p>Next make a Ruby RPM. RPMs are hard. Luckily <a href="https://twitter.com/ianmeyer">Ian Meyer</a> is watching out for us and has a <a href="https://github.com/imeyer/ruby-1.9.3-rpm">defined, working spec</a> from which to build an RPM. I've made this Ruby RPM for two different clients and it compiled without a hitch.</p>

<p>Once you create an RPM, put it into your custom package repo so that you can yum install ruby-1.9.3 or install it via cookbook later.</p>

<p>I repeat this series of steps for the Rubygems tarball, except using <a href="https://github.com/jordansissel/fpm">FPM</a> to package it.  Then they go in my custom repo where the custom repo has a higher priority than my base repo and my recipe just has a package block to install Ruby and Rubygems. It takes about 30 seconds instead of the 5 minutes it takes to compile Ruby from scratch.</p>

<p>If you use Ubuntu, well, they are cooler than EL and have <a href="http://packages.ubuntu.com/quantal/ruby1.9.3">Ruby-1.9.3 packages</a>.</p>

<h2>Where Do We Go From Here?</h2>

<p>An important part of toolchaining is maintaining control of the supply chain.  The way we do that is by creating space for packages and actively managing that space. It should be freely accessible to both deposit and receive software. Don't manage things by locking people out, but by making it easy to use and providing guidelines for usage. Most people want to do the right thing. When you make the right thing easy to do, more people will do it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pieces and Parts: Managing Your Ruby Toolchain (part 1)]]></title>
    <link href="http://blog.brattyredhead.com/blog/2013/05/12/pieces-and-parts-managing-your-ruby-toolchain/"/>
    <updated>2013-05-12T13:12:00-05:00</updated>
    <id>http://blog.brattyredhead.com/blog/2013/05/12/pieces-and-parts-managing-your-ruby-toolchain</id>
    <content type="html"><![CDATA[<p>I recently received an email from someone who attended my <a href="http://www.youtube.com/watch?v=pHmU0aNkENc&amp;list=PLrmstJpucjzXNMLcI5X-EjirpDd-SITd3&amp;index=28">ChefConf talk</a> and asked me to expand on a few things. As I started to answer the email, I could see it was going to turn into a dissertation, so I migrated it over into a blog post.  As I started to write the blog post, it seemed to grow into a book, so now I've decided to break it down into multiple posts.  In this post I'll try to summarize the question and situational environment and cover the easiest answers first: scripting languages and RVM.</p>

<p><strong>The Question</strong><br/>
Given the dynamic nature of Ruby tooling and the uncertainty of internet connections, and given that I work in the Enterprise, how should I design my supporting infrastructure and should I make Ruby my default scripting language?</p>

<p><strong>The Situation</strong><br/>
Situated in the Enterprise, working with Red Hat/CentOS Enterprise Linux(EL).</p>

<p><strong>Concerns</strong>  <br/>
* Rapidly changing versions of gems and software on the internet<br/>
* A constant need to download and compile Ruby (also compilers in production)<br/>
* The dynamic nature of downloading an RVM script from the internet on every install<br/>
* No connection to the internet (I'm not sure if this was a concern of his, but I'm betting it's one of yours)</p>

<p>Let's look at our major parts, shall we? In this set of posts we'll cover <br/>
* <a href="#script">Scripting Languages</a> <br/>
* <a href="#rvm">RVM</a><br/>
* [Package Repositories]  <br/>
* [Package Versions]   <br/>
* [Ruby Management]     <br/>
* [Rubygems]</p>

<p><a id="script"><strong>Scripting Languages</strong></a><br/>
The question was, should we go all in on Ruby as a scripting language? My answer to that is, unless everyone loves Ruby, that's probably an unnecessary hardship to impose while also trying to adopt Chef.  Generally you find some combination of Shell, Python, Perl or Ruby on most enterprise server systems. I think you should script in the language that works best for you, where "works best" is a combination of what you're comfortable with and what will best suit your immediate need.</p>

<p>Honestly I think we'll never move entirely away from Shell scripting and that's ok. It's easy to learn and suits functional tasks like cron jobs and other server-specific work. Do I think you should have a script suite in 4 different interpreted languages? Well, no. If it were me, I'd pick Shell and Ruby for my options. But there's no reason it can't be Shell and Python or any other combo.</p>

<p>Me? I love Ruby and have an irrational dislike of Perl that stems from my early days in ops dealing with travesties of unreadable scripts. So I like Ruby first and Shell second, Python third and Perl never.  But it's hard enough learning a new tool like Chef. Don't impose artificial constraints on your team.</p>

<p>Also, Your devs are probably already programming in Java or C or whatever. Over time most devs pick up a smattering of shell. If you force Ruby on them too it's likely to breed resentment.</p>

<p><a id="rvm"><strong>RVM</strong></a> <br/>
While I'm not an expert on <a href="http://rvm.io">RVM</a> and other Ruby managers, I have heard that it's not meant to be a server tool.  I do use RVM for workstation development and I've used <a href="http://github.com/sstephenson/rbenv/wiki">Rbenv</a> as well. I don't mind compiling Ruby from scratch when installing it locally although I will love it when RVM gets precompiled rubies for OSX.</p>

<h5>A Slight Digression on Workstation Automation</h5>

<p>I've written workstation automation using Fletcher Nichol's <a href="http://github.com/fnichol/chef-rvm">chef-rvm cookbook</a>.  A frustrating problem I have run into is that RVM undergoes frequent development and at first I had people coming to me because the workstation toolchain install wouldn't work and it was almost always because the RVM version had changed and something was now wonky in the settings or install chain. So I started pinning the RVM version to install with occasional revisits to bump the version when I could.</p>

<p>If you want to look at workstation automation for OSX 10.8 try a couple of these repos:</p>

<ul>
<li><a href="http://github.com/pivotal-sprout/sprout-wrap">Sprout-wrap</a> - This used to be Pivotal Workstation and is now basically an instruction page for getting going with Soloist</li>
<li><a href="http://www.solowizard.com">SoloWizard</a> - a browser based checklist that will assemble a chef solo provisioner for your workstation.</li>
<li>Joshua Timberman's workstation-chef-repo and mac_os_x-cookbook for his personal collection of workstation automation</li>
<li><a href="http://github.com/blt04/puppet-rvm">Puppet-RVM</a> - Puppet module for installing and managing RVM</li>
<li><a href="http://boxen.github.com/">Boxen</a> - A tool for automating OSX with Puppet. Links to a blog post with details.</li>
</ul>


<p>I have written workstation automation but I don't maintain it these days and I'll probably try Soloist when I get my next new Mac.</p>

<p><strong>TL;DR</strong>:<br/>
* Use RVM on workstations not servers  <br/>
* If you're automating for many people over time, pin your RVM version</p>

<p><strong>Wrap Up</strong>
To keep the blog post readable, this is all I want to discuss in this first post, but I'm about to publish Part 2 as well: a rant about package repos. I'm extremely interested in feedback on this series as I was only half joking about writing a book, though it would likely be an online doc of some kind. This type of discussion evolves too quickly to commit to paper.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Minneapolis - St Paul Infracoders Meetup Recap]]></title>
    <link href="http://blog.brattyredhead.com/blog/2013/05/07/minneapolis-st-paul-infracoders-meetup-recap/"/>
    <updated>2013-05-07T10:34:00-05:00</updated>
    <id>http://blog.brattyredhead.com/blog/2013/05/07/minneapolis-st-paul-infracoders-meetup-recap</id>
    <content type="html"><![CDATA[<p>Last night we had a fun second meetup of the <a href="http://www.meetup.com/Twin-Cities-Infracoders">Twin Cities Infracoders group</a>.  On the docket were presentations and demos for Vagrant and Sensu.  We had about 18 people show up and a lively discussion ensued on why you'd want to use something like Vagrant and implementation strategies.</p>

<p>Most of us have partnered with development teams who have asked for things that are difficult to provide or unwise and one of the best use cases for Vagrant is the ability to hand someone a development environment homogenous to the team and easy to troubleshoot. It's homogenous because everyone uses the same base OS box file and also uses the same provisioner to create the environment, whether that's Chef, Puppet or Bash scripts or anything else. It also shortens time required to bootstrap a new team member.</p>

<p><a href="http://www.linkedin.com/in/mpgoetz">Mike Goetz</a> and <a href="http://www.linkedin.com/in/thomasduffield">Tom Duffield</a> gave us a great compressed Wordpress install demo on a local VM with Vagrant and Chef. Then they gave us a second demo of spinning up two ec2 instances to separate the front and back end pieces of Wordpress.</p>

<p>After Vagrant, we ran through some Sensu slides and looked at some basic info about Sensu.  There were technical difficulties around the demos we were working on so demoing was minimal but discussion around why Sensu, how Sensu and when you might switch was great and we're looking forward to a more detailed demo at next month's meetup.</p>

<h5>Here is the collection of tools and links from last night:</h5>

<p><a href="http://www.vagrantup.com/">Vagrant</a><br/>
<a href="http://docs.vagrantup.com/v2/plugins/index.html">Vagrant Plugins</a><br/>
<a href="http://sensuapp.org/">Sensu</a><br/>
<a href="http://slides.sensuapp.org/">Sean Porter's Slides</a><br/>
Wordpress Demo(this link will be available shortly)</p>

<h5>Coming up:</h5>

<p>Next month's meetup, hosted again at the Nerdery, will be a presentation on using Selenium for automated testing and QA as well as our enhanced Sensu Server and client nodes deployed with Vagabond on LXCs inside a Vagrant VM.  I hope we get a great turnout.</p>

<p>On another note, I have been talking lately about how I want to organize a Chef hackday. After last night's discussions around tooling and workflow, I think it might be nice to instead do a tool-agnostic Workflow Tooling hack and help day. Many of us have gotten workflows configured successfully, but depending on your experience beating on the Ruby toolchain, it can be challenging the first couple times you do it.  The Nerdery said they would probably be willing to host and I was thinking about asking CoCo Minneapolis if they had any interest in hosting.</p>

<p>I'll post up a question in the meetup group about location and date preferences to see if I get enough interest to make it a thing. I'll also send someone to shill at the monthly DevOps meetup that I can never attend due to my work travel schedule.</p>

<p>If you haven't made it out to an Infracoder meetup yet, I hope you because we are having some great tech discussions and getting to hear about other people's uses cases for things is fascinating. Also, the Nerdery takes super great care of us and feeds us Pizza for dinner.</p>
]]></content>
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: packages | Bratty Redhead]]></title>
  <link href="http://sbates.github.com/sbates/blog/categories/packages/atom.xml" rel="self"/>
  <link href="http://sbates.github.com/sbates/"/>
  <updated>2017-08-18T12:43:54-07:00</updated>
  <id>http://sbates.github.com/sbates/</id>
  <author>
    <name><![CDATA[Sascha Bates]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ruby Toolchaining Part 3: Walking the Package Talk]]></title>
    <link href="http://sbates.github.com/sbates/blog/2013/05/24/ruby-toolchaining-part-3-walking-the-package-talk/"/>
    <updated>2013-05-24T03:16:00-07:00</updated>
    <id>http://sbates.github.com/sbates/blog/2013/05/24/ruby-toolchaining-part-3-walking-the-package-talk</id>
    <content type="html"><![CDATA[<p>This is the third post in a series about managing your Ruby Toolchain. Expect at least one more after this. You can also read:<br/>
<a href="http://blog.brattyredhead.com/blog/2013/05/12/pieces-and-parts-managing-your-ruby-toolchain">Pieces and Parts: Managing Your Ruby ToolChain(part 1)</a> <br/>
<a href="http://blog.brattyredhead.com/blog/2013/05/17/managing-your-ruby-toolchain-part-2-the-package-repo-rant">Managing Your Ruby Toolchain Part 2: The Package Repo Rant</a></p>

<p>Why I rant about package repositories: Static software without a repository is the pebble that becomes an avalanche. So many undesirable behaviors stem from no one owning the package collection.  Read the rant if you want details.  This is a practical discussion, although I'm not telling you what to do. I'm just telling you what I've done and what I've seen over the course of my career.  There are many ways to solve this problem. Do what works for you.</p>

<p>This post grew so much that there is one more after it that specifically deals with some toolchaining tools and ideas as well as a few anecdotes on how I've dealt with some of these challenges in the past.</p>

<p>Today we're going to talk about:<br/>
<a href="#tarballs">Tarball Orphans vs Artifacts vs Inbetweeners</a>  <br/>
<a href="#internet">The Internet</a><br/>
<a href="#repos">An Approach to Repositories</a>  <br/>
<a href="#packing">Packaging Tarballs</a>  <br/>
<a href="#ruby">Ruby Management</a>   <br/>
<a href="#toolchaining">Ruby Toolchain Management</a></p>

<h2><a id="tarballs">Tarball Orphans</a></h2>

<p>What do I mean when I rant about tarballs? Basically I mean that pile of source you downloaded from the internet, or Tomcat package, JBoss tarball, Ruby source, whatever.</p>

<p>What is exempt from my ranting  wrath? Custom code that you might tar up instead of jar/ear/war.  Anything that changes often shouldn't be in our static package repository. Those are places to keep long term, install-once per server software.</p>

<p>When I talk about tarballs, I mean tumbleweed off the internet.  When I refer to compiled code I'll use the word <strong>artifact</strong>.  What's an artifact? It might be a jar file you bundle with your deployed code. It might be a war file. It might be a tar of ruby code Or database artifacts.  Anything that's your stuff, we don't put that into package repositories.  We put it into artifact repositories like Artifactory and Nexus. People also use S3 storage to store and retrieve artifacts.</p>

<p>Some things may not be easily categorized. Newer products get frequent updates that may require frequent patches or deployments. For example, I worked with a team that implemented Basho's <a href="http://basho.com/">Riak</a> which they updated frequently and ended up engaged in a disagreement with Ops on how often they could update it. The ops team wanted to restrict it to quarterly and the devs wanted much more frequently. This sort of management requires a custom solution that may be package-based or not.</p>

<h2><a id="internet">The Internet</a></h2>

<p>If your infrastructure has free access to the internet, that's awesome. Many infrastructures have limited or no access to the internet.  Often the reasons for this seem silly.  But sometimes you can't fight city hall, or you can but you need to save your fights for the life or death kind.  Your servers don't need the internet to survive. Or they should not.</p>

<p>Eventually you will find yourself needing stuff from the Internet. In order to work within restrictions, you can set up a <a href="http://en.wikipedia.org/wiki/Bastion_host">Bastion</a> host or AWS VPC infrastructure that can call out to the internet in order to create private mirrors of any repositories you need.  You can follow the slightly more difficult path of setting up an internal server that contains your repos that you need to sync in a way that doesn't have direct access to the internet.</p>

<p><strong>Internet as Troublemaker</strong><br/>
Internet access brings its own set of problems as well. If you aren't specific about package versions, with every server provision you could have slightly different versions of things installed.  This is a problem because it can cause erratic behavior across your infrastructure. If you have 1000 nodes built over the course of six months, each build wave can introduce incremental differences. When you control the packages in your internal repos, you exert a stabilizing effect, which is a good way to control your system without making it brittle.</p>

<p>Even if sloppy package management doesn't actually cause issues, it will be a suspect in any intermittent, mysterious problems. Picture an outage conference bridge including execs. Now envision yourself explaining to them how this mismatch isn't a problem. Can you envision any explanation that doesn't make you sound like a dolt?</p>

<p><strong>Example</strong>: A few years ago JBoss 5 shipped with a bug that was a major performance blocker but difficult to track down. It was later fixed in a minor patch release. Imagine having a JBoss package block that just says <code>package "jboss" {action :install}</code> and using an internet repo to install it. 6 months later you provision 100 servers from your trusty internet repo and over your peak season, the bug triggers but everything is weird because it's only a problem on some servers.  Imagine tracking this down. (Yes this is a flawed example b/c as far as I know, there's no internet repo with a JBoss rpm)</p>

<p>If you're a dev and you think this isn't a problem, try chatting with a friend in the sysadmin/ops area before you poo-poo. If you're a sysadmin and you think this isn't a big deal, may we never be responsible for the same infrastructure.</p>

<p><strong>Be Conservative.</strong> As a rule it's ok to use external signed key repositories for your base OS packages as those shouldn't change. Tread carefully even with patch/update servers to ensure homogenous installs and any packages acquired from other internet repos (like EPEL) should be installed with explicit versions.</p>

<p><strong>Adopt Orphans</strong> Don't let Internet-sourced software roam around your infrastructure unsupervised. If you need a package from the internet, it should be easy enough to download and insert into your custom repository. There are several tools for managing repositories. For Enterprise Linux, <a href="https://github.com/cobbler/">Cobbler</a>, the provisioning and infrastructure management tool has repository management and mirroring. My new favorite thing for this though is a tool called <a href="http://pulpproject.org/">Pulp</a>, an open source project by Red Hat.  If you prefer simplicity, you can just install a web proxy and use a command line tool like <code>createrepo</code> to manage your yum repos.</p>

<p><strong>Don't assume I can talk to the Internet.</strong> When it comes to configuration management tools, I find it in bad taste to write a module or cookbook intended for the community with an Internet dependency.  If you have to write one, label the dependency in large font.</p>

<h2><a id="repos">An Approach to Repos</a></h2>

<h3>OS Packages</h3>

<p>If you're going to set up repositories, consider a collection like this list.</p>

<p><strong>Base</strong> - base EL install repo  - This is generally straight up ISO content<br/>
<strong>Patch</strong> - repository containing patches<br/>
<strong>EPEL</strong> - EL Extras repo mirror<br/>
<strong>Custom</strong> - repository containing all the custom packages I need that I've either crafted myself or downloaded</p>

<p><strong>Purity of Purpose:</strong> Always keep your base and patch repos pure. Don't let people just dump random packages into a Base OS collection. You'll never know what was supposed to be there and what was added later.</p>

<p><strong>Prioritization and Specificity:</strong> If you have two versions of a package in different repos, either be specific when installing or configure a priority for each repo.</p>

<h3>Rubygems</h3>

<p>This is where you get/put your gems. Gem is the package manager for Rubygems. You either need to connect to the internet to get all of these things or you need internal package repos/mirrors.  See this <a href="http://davidmoulton.me/2011/02/07/create-a-private-gem-repository.html">blog post</a> by David Moulton for how easy it is to set up a rubygems repo.</p>

<h3>Artifacts</h3>

<p>This is where your deployment artifacts, jar, war, ear files should be contained; a tool where it's easy to retreive them programmatically. I have seen people use <a href="http://www.sonatype.org/nexus/">Nexus</a>, <a href="http://www.jfrog.com/">Artifactory</a> and even S3 to store artifacts. If you're not a java shop, you may not need something this complex. My major experience is with Java shops.</p>

<h3>YMMV</h3>

<p>There are many ways to craft your infrastructure. Having package repositories is an advantage because they make it really obvious to everyone in your organization where to look for software and where they should put software they need.</p>

<p>The important thing to keep in mind here is that, especially if you're in the Enterprise, you aren't designing for yourself or just one team. This will balloon out to include dev teams using your tools. In order to deploy their app, the devs will test using VMs provisioned by your infrastructure and they should be taking advantage of your beautiful repos to deposit their extra software packages.  Your team may even be administering the VM infrastructure.</p>

<p>A major goal to strive for is for all VMs and servers to be provisioned the same way in all environments, desktop to production. You make this easiest and more likely to happen when you make it easy to interact with software repositories.  If it's not easy, other teams will "figure something out" which will likely outrage you when you discover it.</p>

<h2><a id="packing">Practical Tarball Management</a></h2>

<h3>Avoid Compiling From Source</h3>

<p>Believe me when I say that you <strong>do not</strong> want to compile Ruby from scratch every time you build a server. The more automation achievements you unlock, the easier it becomes to use ephemeral VMs.  In Dev, people should be popping up and killing VMs all the time. If it takes 10 minutes to build a server, they won't be doing this, dev VMs will have <a href="http://workstuff.tumblr.com/post/50911984233/some-tips-on-getting-started-with-vagrant-and-chef">major cruft buildup</a> and dismay will ensue when people realize they can't actually reproduce their dev VM.</p>

<h3>Turning a Tarball into a Package</h3>

<p>How do you get packages for your repos when all you have is a pile of tarballs? If you're brilliant, write a package spec for it. If you're like the rest of us, you use <a href="https://github.com/jordansissel/fpm">FPM</a>.  Even if you are in a situation where you can't have a package repo, you can at least create and store packages which will speed up installation and simplify implementation.</p>

<p><a href="https://github.com/jordansissel/fpm">FPM</a>: Learn it, love it, live it.</p>

<h3><a id="ruby">Ruby Management</a></h3>

<h3>Ruby Source</h3>

<p><strong>1.8.7 is EOL</strong><br/>
First, on the topic of existing packages, as <a href="http://www.ruby-lang.org/en/news/2011/10/06/plans-for-1-8-7/">announced in October of 2011</a>, Ruby 1.8.7 is officially end of life and won't even get security updates after June 2013.  <em>Just say no to the supplied 1.8.7 packages</em> on your Enterprise Linux(EL) and the one that comes installed with OSX. No really, never touch it. If you're using it, start seriously considering how to move on.</p>

<p><strong>System Ruby</strong><br/>
Whatever else you're doing, your servers will all want a system Ruby. It's possible to get along without this(see omnibus in subsequent sections), but especially in dev, people will be shocked and dismayed when there's no easily accessible Ruby.  So get you some Ruby, not from the ancient EL repos, but get the source tarball from <a href="http://www.ruby-lang.org/en/">Ruby-Lang.org</a>.</p>

<p>Why do I tell you this obvious thing? We had the brilliant idea of switching out our compile-every-time system ruby install with just using the embedded Ruby that ships with Chef client. Never do this. The trouble is that your Ruby install is not just an executable, but a name space for installing gems and related software. This is is why Chef ships in an omnibus in the first place: to avoid dependency hell and version conflicts.  The other problem with this idea is that you are still lacking a system Ruby. You either have symlink to the Ruby executable or people have to know where to look for. So install a system Ruby independent of any other software.</p>

<p>Next make a Ruby RPM. RPMs are hard. Luckily <a href="https://twitter.com/ianmeyer">Ian Meyer</a> is watching out for us and has a <a href="https://github.com/imeyer/ruby-1.9.3-rpm">defined, working spec</a> from which to build an RPM. I've made this Ruby RPM for two different clients and it compiled without a hitch.</p>

<p>Once you create an RPM, put it into your custom package repo so that you can yum install ruby-1.9.3 or install it via cookbook later.</p>

<p>I repeat this series of steps for the Rubygems tarball, except using <a href="https://github.com/jordansissel/fpm">FPM</a> to package it.  Then they go in my custom repo where the custom repo has a higher priority than my base repo and my recipe just has a package block to install Ruby and Rubygems. It takes about 30 seconds instead of the 5 minutes it takes to compile Ruby from scratch.</p>

<p>If you use Ubuntu, well, they are cooler than EL and have <a href="http://packages.ubuntu.com/quantal/ruby1.9.3">Ruby-1.9.3 packages</a>.</p>

<h2>Where Do We Go From Here?</h2>

<p>An important part of toolchaining is maintaining control of the supply chain.  The way we do that is by creating space for packages and actively managing that space. It should be freely accessible to both deposit and receive software. Don't manage things by locking people out, but by making it easy to use and providing guidelines for usage. Most people want to do the right thing. When you make the right thing easy to do, more people will do it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Managing Your Ruby Toolchain part 2: The Package Repo Rant]]></title>
    <link href="http://sbates.github.com/sbates/blog/2013/05/17/managing-your-ruby-toolchain-part-2-the-package-repo-rant/"/>
    <updated>2013-05-17T09:23:00-07:00</updated>
    <id>http://sbates.github.com/sbates/blog/2013/05/17/managing-your-ruby-toolchain-part-2-the-package-repo-rant</id>
    <content type="html"><![CDATA[<p><strong>TL;DR</strong> Use package repos for all your static software</p>

<p>Last weekend I wrote a <a href="http://blog.brattyredhead.com/blog/2013/05/12/pieces-and-parts-managing-your-ruby-toolchain/">blog post</a> that started exploring standards for managing your Ruby toolchains. To review, I had a query from someone on how to cope with the dynamic nature of Ruby-based tooling and managing a Chef infrastructure. and the fact that you don't always want to go to the internet to get stuff, it's a pain to be compiling things on servers all the time AND to do that, you need a compiler which is regarding as a Bad Thing<sup>TM</sup> in Production.</p>

<p>The question came to me via a talk I did at Chef conf and I'm going to use Chef examples, but, unless someone tells me different, I'm going to come down on the side of you can use this advice with Puppet and CFEngine and any other CM tool out there. It works without CM too, but why would you ever?</p>

<p>In this blog post, I want to talk about why I am so adamant about package repositories and offer some real world examples.  I pick on Tomcat a lot here. Nothing against Tomcat. It's something most people understand and that I have also had personal experience with it not being managed as a package and creating much distributed pain.</p>

<h2>Broken Record Much?</h2>

<p>I can't shut up about package repos. Why am I so passionate about the need for all package repos all the time and to have a team actively managing and grooming them?</p>

<p>As part of the decentralization of Ops teams and the rise of DevOps, we now see multiple autonomous teams simultaneously working on similar projects but not collaborating or communicating on infrastructure.  It behooves the infrastructure managers, whether that's ops or devops or the tools team or a central collaborative group comprised of reps from all the teams, to own and groom a collection of package repositories.</p>

<p><strong>But Why?</strong> <br/>
With the rise of self-service, all you can eat virtual machines, development teams are expected and want to be independent from the corporate server supply chain.  Unfortunately this also decouples them from people they depend on: infrastructure and middleware experts(Yes Ops, that's you). They may sail gayly on and do their best or trudge forward grudgingly, resenting all of the extra work they now have to do because the Enterprise wants to be "like a startup." Either way, they're going to move forward, and when you don't offer them ways to easily use software, they'll figure out ways to [cope][]; ways that will horrify you when you discover them.</p>

<p><strong>I work at a startup because Enterprise is stupid like that.</strong><br/>
Nope. It's not only the Enterprise that needs to fear the chaos of unmanaged, difficult to use infrastructure. Say your whole startup is fewer than 20 people? You're the "devops engineer" and you work with a 5 person dev team.  The dev team may or may not include you in everything.  You might not know of actions they've taken to [cope][] with problems you don't even know they have. They don't realize there could be a simple solution to their problems because they are brilliant startup devs and they will just figure it out.  Then they'll hand you their giant shiny mud pie and you will cry because you could have saved them a bunch of work with a few well placed repos and a web proxy.</p>

<p>Package repos create a beautiful garden where you static software can flourish and discourages tarball weeds from springing up in the cracks everywhere.</p>

<p><strong>If you establish a well known, central location for packages, people will know to look there first for an existing package that meets their needs. And they will ask to place packages they need there as well.</strong></p>

<p>Ex: In the situation where someone thinks</p>

<blockquote><p><em>"I need Tomcat7 and Red Hat only ships with Tomcat5"</em></p></blockquote>

<p>Their correlating thought will NOT be</p>

<blockquote><p><em>"I should go download that from the internet and store it on the jumphost"</em></p></blockquote>

<p>but instead</p>

<blockquote><p><em>"I wonder if we have that in our custom repo?"</em></p></blockquote>

<p>or in an even more mature organization</p>

<blockquote><p><em>"I should include our Tomcat cookbook in my runlist and override the attributes that are unique for my situation"</em></p></blockquote>

<h3>When you make package repos easy to access and use, you</h3>

<ul>
<li>Eliminate several slightly different copies of software (ex: tomcat) floating around your infrastructure.</li>
<li>Eliminate several slightly different versions of packages deployed to Production.</li>
<li>Discourage placing random tarballs in version control or Chef cookbook files.</li>
<li>Make your configuration management tool easy and intuitive to use.</li>
</ul>


<h3>The Problem With Tarballs - a Real Life Example</h3>

<p>Config management tools are designed to be idempotent, which means they only do things once and ensure things look the same regardless of how many times you run the the same process.  <em>Tarballs subvert the use of configuration management primitives</em>, requiring the use of non-idempotent execute blocks to manipulate them.  Real world example:</p>

<p>Without a package repo in place, this happens:
``` ruby
remote_file "/tmp/tomcat7.tar.gz" do
  source "https://www.sometomcaturl.com"
  not_if { File.exists?("#{node[:tomcat][:home]}/bin") }
end</p>

<p>execute "extract_tomcat" do
  command "tar xf /tmp/tomcat7.tar.gz"
  cwd "opt"
  not_if { File.exists?("#{node[:tomcat][:home]}/bin") }
  only_if { File.exists?("/tmp/tomcat7.tar.gz") }
end
```</p>

<p>Or this utter travesty:
``` ruby
bash "install_tomcat6" do</p>

<pre><code>tomcat_version_name = "apache-tomcat-#{node.tomcat.version}"
tomcat_version_name_tgz = "#{tomcat_version_name}.tar.gz"
user "root"
code &lt;&lt;-EOH
  curl --proxy https://aproxy.com:8080/ --user user:pass https://myartifactoryurl.com/artifactory/ext-release-local/apache-tomcat/apache-tomcat/#{node.tomcat.version}/#{tomcat_version_name_tgz} -o /tmp/#{tomcat_version_name_tgz}
  tar -zxf /tmp/#{tomcat_version_name_tgz} -C /tmp
  rm /tmp/#{tomcat_version_name_tgz}
  mv /tmp/#{tomcat_version_name} #{node.tomcat.install_path}
  chown -R #{node.tomcat.run_user}:#{node.tomcat.run_group} #{node.tomcat.install_path}
  chmod -R 755 #{node.tomcat.install_path}
  rm -rf #{node.tomcat.install_path}/webapps/ROOT
EOH
</code></pre>

<p>end
```
Notice that they very carefully delete that tarball when they are done, ensuring that it will be re-downloaded 30 minutes later on the next run. They also untar the file and then move it to the install location without checking to see if anything is already there.  Again, 30 minutes later the entire process happens again despite whatever is already there.</p>

<p>Now look at what happens with a package repo in place:
<code>ruby
package 'tomcat7' do    
  action :install  
end  
</code>
You may have to customize config files and init scripts, but this is a far simpler and less error prone way to install the base software.</p>

<p>In this case, Chef knows what OS you are using, what your package manager should be, repository connection details and how to install the package. Puppet does the exact same thing. So does every other config management system in the history of ever.  The less code you have to write and the less verification code you have to write, they happier you'll be and the people who come after you will be.</p>

<h3>The End</h3>

<p>I've heard a lot of complaints from ops and tools folks that devs do "crazy" stuff and they are much affronted that the devs don't seem to understand the unpublished rules of operationalizing apps and the best way to use tools, and omg did you see the travesty of a Tomcat cookbook they wrote?</p>

<p>I have spent years on ops teams, tools teams and automation teams now. I have been one of those self-righteous, affronted peeps.  This behavior doesn't scale, yo.</p>

<p>One of the best messages that DevOps has for all of us is, if you don't like the way someone's doing something, talk to them and find out why. You'll probably learn that there were great reasons for everything, including "I didn't know how to do it, Chef is hard, Tomcat is hard, and I was just a Java developer until you guys started making me do all this automation stuff without telling me the rules or offering guidelines, so I copied another team's Tomcat cookbook. I had no idea it's crap. It installs Tomcat and that's all I care about."</p>

<p>Indeed. That's all they care about. If you care about more than just the install, maybe you should reach out and offer to partner with them on the parts you care about.  Don't like the way devs are building application infrastructure? Well maybe you should do it for them. Provide them with a consistant VM build from a stable package repo and possibly infrastructure cookbooks with sane defaults and overrideable parameters. Chances are good devs don't like recreating that crappy Tomcat wheel any more than you like them doing it. It's likely they will be pathetically grateful because, while they are coping with the tasks they've been handed, they don't really know what to do in detail and researching JVM tuning parameters is not their idea of a good time.</p>

<p>Why am I telling you this story? Because I believe that a major piece of your infrastructure stability is created with package repos. Making them easy to find, use and contribute to will help smooth any number of peripheral problems you are trying to solve.  In my next post I'll talk about practical considerations for repositories, packages and toolchains.</p>
]]></content>
  </entry>
  
</feed>
